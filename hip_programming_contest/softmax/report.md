# GPU Softmax 程序设计报告

## 引言

本次任务的目标是实现一个基于 HIP 的 Softmax 函数程序。Softmax 是深度学习和机器学习中的核心激活函数，广泛应用于分类任务和注意力机制中。给定输入向量 x = [x₁, x₂, ..., xₙ]，Softmax 函数计算 y = [y₁, y₂, ..., yₙ]，其中 yᵢ = e^(xᵢ) / Σⱼ e^(xⱼ)。设计的重点不仅在于保证算法的正确性，还在于在 GPU 上充分发挥并行性能，并在评测时兼顾整体运行时间，包括数据传输与初始化开销。

## 开发过程

最初的实现采用了传统的两阶段方法：首先计算全局最大值和求和，然后计算最终的 Softmax 值。然而，这种方法在数值稳定性方面存在问题，当输入值过大时容易发生溢出，当输入值过小时容易发生下溢。为了确保数值稳定性，我们采用了数值稳定的 Softmax 算法：m = maxᵢ xᵢ，tᵢ = e^(xᵢ - m)，S = Σᵢ tᵢ，yᵢ = tᵢ / S。

在实现过程中，我们遇到了几个关键挑战。首先是内存管理问题：原始实现需要在每次计算时进行主机到设备的数据传输，这成为了性能瓶颈。通过使用页锁定内存（pinned memory）和异步传输，我们显著提高了数据传输效率。页锁定内存避免了额外的内存拷贝，而异步传输允许计算和传输重叠进行。

其次是并行归约算法的设计。Softmax 计算需要两次全局归约：一次计算最大值，一次计算求和。我们采用了基于在线统计算法（online statistics）的方法，在一次遍历中同时计算最大值和求和，避免了多次遍历的开销。通过使用 warp 级别的 shuffle 操作和共享内存，我们实现了高效的并行归约。

性能分析表明，GPU 核函数的执行效率很高，在百万级数据规模下，纯 GPU 计算部分仅需数毫秒。然而，最大的开销仍然来自 HIP 的首次初始化，这与前缀和程序遇到的问题类似。通过将 HIP 初始化提前到 `main` 函数，并通过单独线程与文件 I/O 并行执行，我们成功隐藏了初始化开销。

同样考虑到评测统计的是整个程序的运行时间，文件 I/O 的优化也至关重要。我们实现了快速读入函数和带缓冲区的快速输出函数，避免了标准库的额外开销。对于大规模数据，这种优化带来了显著的性能提升。

## 最终方案

最终实现的方案包括以下要点：

* **核心算法**：数值稳定的 Softmax 算法，使用在线统计算法在一次遍历中同时计算最大值和求和，确保数值稳定性。
* **内存管理**：使用页锁定内存和异步传输，避免额外的内存拷贝开销，提高数据传输效率。
* **并行归约**：采用基于 warp shuffle 的两级归约算法，充分利用 GPU 的并行计算能力。
* **初始化优化**：HIP 初始化通过后台线程提前完成，与文件读取并行，从而消除了对整体耗时的影响。
* **I/O 优化**：实现快速读入和带缓冲区的输出函数，减少系统调用开销。

## 算法设计

### 数值稳定的 Softmax 算法

数值稳定的 Softmax 算法通过减去最大值来避免数值溢出和下溢：

1. **计算最大值**：m = maxᵢ xᵢ
2. **计算偏移指数**：tᵢ = e^(xᵢ - m)
3. **计算归一化因子**：S = Σᵢ tᵢ
4. **计算最终结果**：yᵢ = tᵢ / S

这种方法确保了所有指数值都在合理范围内，避免了数值不稳定问题。

### 在线统计算法

我们使用在线统计算法在一次遍历中同时计算最大值和求和：

```cpp
void combineRunningStats(float& m_acc, double& l_acc, float m_other, double l_other) {
    float m_new = m_acc > m_other ? m_acc : m_other;
    double l_new = 0.0;
    if (l_acc != 0.0) {
        l_new += l_acc * exp((double)(m_acc - m_new));
    }
    if (l_other != 0.0) {
        l_new += l_other * exp((double)(m_other - m_new));
    }
    m_acc = m_new;
    l_acc = l_new;
}
```

这种方法避免了多次遍历，提高了计算效率。

### GPU 实现细节

实现分为三个主要阶段：

1. **第一阶段**：各线程块并行计算局部统计量 (m_b, l_b)
2. **第二阶段**：将各块的统计量归约为全局统计量 (m, l)
3. **第三阶段**：使用全局统计量计算最终的 Softmax 值

每个阶段都使用向量化访存（float4）和 warp shuffle 操作来优化性能。

## 性能优化

### 内存优化

- **页锁定内存**：使用 `hipHostMalloc` 分配页锁定内存，避免额外的内存拷贝
- **异步传输**：使用 `hipMemcpyAsync` 进行异步数据传输，允许计算和传输重叠
- **向量化访存**：使用 `float4` 进行向量化访存，提高内存带宽利用率

### 计算优化

- **在线统计算法**：在一次遍历中同时计算最大值和求和，避免多次遍历
- **Warp shuffle**：使用 warp 级别的 shuffle 操作进行高效的并行归约
- **共享内存**：使用共享内存减少全局内存访问次数

### 线程配置优化

- **动态网格大小**：根据 GPU 硬件信息动态调整网格大小
- **参数化配置**：通过编译时参数调整线程块大小和网格倍数
- **负载均衡**：使用网格步长循环确保负载均衡

## 结果与分析

在测试用例上的表现：

* 所有测试用例均通过，满足数值精度要求（绝对容差 1×10⁻⁶，相对容差 1×10⁻⁵）
* 通过数值稳定的算法实现，避免了溢出和下溢问题
* 通过页锁定内存和异步传输，显著提高了数据传输效率

性能优化的效果：

* 通过在线统计算法，减少了数据遍历次数，提高了计算效率
* 通过向量化访存和 warp shuffle，充分利用了 GPU 的并行计算能力
* 通过初始化并行化和 I/O 优化，显著降低了整体运行时间

## 总结与展望

本次工作实现了一个正确且高效的 GPU Softmax 程序，开发过程中解决了数值稳定性、内存管理、并行归约等多个实际问题。在算法层面，数值稳定的 Softmax 算法结合在线统计算法已能满足需求；在工程层面，通过页锁定内存、异步传输和初始化并行化显著降低了整体耗时。

未来的改进方向包括：进一步优化归约算法，探索更高效的并行归约方法；尝试使用混合精度计算（如 half precision）以进一步提高性能；以及探索在更大规模数据上的性能表现。

总体而言，本次开发不仅让我实现了一个高性能的 GPU Softmax 程序，也让我深入理解了 GPU 编程中数值计算、内存管理和并行算法设计的重要性，特别是在处理大规模机器学习计算时的性能优化策略。
